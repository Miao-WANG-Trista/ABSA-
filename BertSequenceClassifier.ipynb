{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_6XzWCI1hhL","executionInfo":{"status":"ok","timestamp":1647184425171,"user_tz":-60,"elapsed":18915,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"bf2a5ca6-744c-4779-f89e-cae14d8a490f"},"id":"R_6XzWCI1hhL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install pytorch_pretrained_bert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kss0_he1yvA","executionInfo":{"status":"ok","timestamp":1647184481998,"user_tz":-60,"elapsed":11353,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"1ad2cfa1-4f43-447a-d0b6-6d21947839f1"},"id":"6kss0_he1yvA","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.10.0+cu111)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.63.0)\n","Collecting boto3\n","  Downloading boto3-1.21.18-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 54.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n","Collecting botocore<1.25.0,>=1.24.18\n","  Downloading botocore-1.24.18-py3-none-any.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 25.1 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.1 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.18->boto3->pytorch_pretrained_bert) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 77.0 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.18->boto3->pytorch_pretrained_bert) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 74.1 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.21.18 botocore-1.24.18 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.2 urllib3-1.25.11\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EU9bjKyv2QXz","executionInfo":{"status":"ok","timestamp":1647184530085,"user_tz":-60,"elapsed":7784,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"5a3325e1-59c6-42b2-b8bd-25b3ba8b860a"},"id":"EU9bjKyv2QXz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 28.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 63.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 68.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 60.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n"]}]},{"cell_type":"code","execution_count":null,"id":"95cc1c1e","metadata":{"ExecuteTime":{"end_time":"2022-03-13T10:18:10.633170Z","start_time":"2022-03-13T10:18:10.615040Z"},"id":"95cc1c1e"},"outputs":[],"source":["import pandas as pd\n","import spacy\n","from tqdm import tqdm\n","from pytorch_pretrained_bert.optimization import BertAdam\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n","import torch\n","from transformers import AutoModel, AutoTokenizer\n","import numpy as np\n","from torch.utils.data import Dataset, TensorDataset, RandomSampler, SequentialSampler, DataLoader"]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"N14E4v301vWa"},"id":"N14E4v301vWa","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"70485c99","metadata":{"ExecuteTime":{"end_time":"2022-03-13T09:22:21.783780Z","start_time":"2022-03-13T09:22:21.748298Z"},"id":"70485c99"},"outputs":[],"source":["train_set = pd.read_csv('/content/drive/Shareddrives/NLP/ASBA/data/traindata.csv',sep='\\t',names=['polarity','aspect','target','offset','sentence'])"]},{"cell_type":"code","execution_count":null,"id":"68f5469f","metadata":{"ExecuteTime":{"end_time":"2022-03-13T09:22:22.485240Z","start_time":"2022-03-13T09:22:22.475910Z"},"id":"68f5469f"},"outputs":[],"source":["val_set = pd.read_csv('/content/drive/Shareddrives/NLP/ASBA/data/devdata.csv',sep='\\t',names=['polarity','aspect','target','offset','sentence'])"]},{"cell_type":"code","execution_count":null,"id":"ccf6595f","metadata":{"ExecuteTime":{"end_time":"2022-03-13T09:22:23.451038Z","start_time":"2022-03-13T09:22:23.433147Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"ccf6595f","executionInfo":{"status":"ok","timestamp":1647184562920,"user_tz":-60,"elapsed":207,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"bd069514-f7e1-49e4-9dde-29b5b19c75e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["positive    0.701929\n","negative    0.259481\n","neutral     0.038589\n","Name: polarity, dtype: float64"]},"metadata":{},"execution_count":12}],"source":["train_set['polarity'].value_counts(normalize = True)"]},{"cell_type":"code","execution_count":null,"id":"da8c29ac","metadata":{"ExecuteTime":{"end_time":"2022-03-13T09:22:24.323503Z","start_time":"2022-03-13T09:22:24.304831Z"},"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"da8c29ac","executionInfo":{"status":"ok","timestamp":1647184565237,"user_tz":-60,"elapsed":11,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"38b9a4ad-7383-467e-acaf-f8c5219129d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   polarity              aspect     target  offset  \\\n","0  positive    AMBIENCE#GENERAL    seating   18:25   \n","1  positive    AMBIENCE#GENERAL  trattoria   25:34   \n","2  positive        FOOD#QUALITY       food  98:102   \n","3  negative     SERVICE#GENERAL      STAFF    5:10   \n","4  positive  FOOD#STYLE_OPTIONS       menu     4:8   \n","\n","                                            sentence  \n","0  short and sweet – seating is great:it's romant...  \n","1  This quaint and romantic trattoria is at the t...  \n","2  The have over 100 different beers to offer thi...  \n","3                        THIS STAFF SHOULD BE FIRED.  \n","4  The menu looked great, and the waiter was very...  "],"text/html":["\n","  <div id=\"df-6cc7431e-219e-4aad-a10a-45c0c02fa975\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>polarity</th>\n","      <th>aspect</th>\n","      <th>target</th>\n","      <th>offset</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>positive</td>\n","      <td>AMBIENCE#GENERAL</td>\n","      <td>seating</td>\n","      <td>18:25</td>\n","      <td>short and sweet – seating is great:it's romant...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>positive</td>\n","      <td>AMBIENCE#GENERAL</td>\n","      <td>trattoria</td>\n","      <td>25:34</td>\n","      <td>This quaint and romantic trattoria is at the t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>positive</td>\n","      <td>FOOD#QUALITY</td>\n","      <td>food</td>\n","      <td>98:102</td>\n","      <td>The have over 100 different beers to offer thi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>negative</td>\n","      <td>SERVICE#GENERAL</td>\n","      <td>STAFF</td>\n","      <td>5:10</td>\n","      <td>THIS STAFF SHOULD BE FIRED.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>positive</td>\n","      <td>FOOD#STYLE_OPTIONS</td>\n","      <td>menu</td>\n","      <td>4:8</td>\n","      <td>The menu looked great, and the waiter was very...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cc7431e-219e-4aad-a10a-45c0c02fa975')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6cc7431e-219e-4aad-a10a-45c0c02fa975 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6cc7431e-219e-4aad-a10a-45c0c02fa975');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["train_set.head(5)"]},{"cell_type":"code","execution_count":null,"id":"58797211","metadata":{"ExecuteTime":{"end_time":"2022-03-13T13:43:55.812778Z","start_time":"2022-03-13T13:43:55.789657Z"},"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"58797211","executionInfo":{"status":"ok","timestamp":1647184566924,"user_tz":-60,"elapsed":199,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"4c32820f-267c-4761-c32d-7306143ee10a"},"outputs":[{"output_type":"stream","name":"stdout","text":["length of train set 1503\n","length of test set 376\n"]}],"source":["print('length of train set',len(train_set))\n","print('length of test set',len(val_set))\n"]},{"cell_type":"markdown","id":"e8559462","metadata":{"id":"e8559462"},"source":["# BERT-based"]},{"cell_type":"markdown","id":"8b548efa","metadata":{"id":"8b548efa"},"source":["## Original data (Please ignore)"]},{"cell_type":"code","execution_count":null,"id":"b579d222","metadata":{"ExecuteTime":{"end_time":"2022-03-12T17:07:47.631318Z","start_time":"2022-03-12T17:07:47.600012Z"},"id":"b579d222"},"outputs":[],"source":["# def parse_SemEval14(fn):\n","#     root=ET.parse(fn).getroot()\n","#     corpus=[]\n","#     opin_cnt=[0]*len(polar_idx)\n","#     for sent in root.iter(\"sentence\"):\n","#         opins=set()\n","#         for opin in sent.iter('aspectTerm'):\n","#             if int(opin.attrib['from'] )!=int(opin.attrib['to'] ) and opin.attrib['term']!=\"NULL\":\n","#                 if opin.attrib['polarity'] in polar_idx:\n","#                     opins.add((opin.attrib['term'], int(opin.attrib['from']), int(opin.attrib['to']), opin.attrib['polarity'] ) )\n","#         for ix, opin in enumerate(opins):\n","#             opin_cnt[polar_idx[opin[3] ] ]+=1\n","#             corpus.append({\"id\": sent.attrib['id']+\"_\"+str(ix), \"sentence\": sent.find('text').text, \"term\": opin[0], \"polarity\": opin[-1]})\n","#     print (opin_cnt)\n","#     print (len(corpus))\n","#     return corpus"]},{"cell_type":"code","execution_count":null,"id":"de447bee","metadata":{"ExecuteTime":{"end_time":"2022-03-12T17:08:11.963568Z","start_time":"2022-03-12T17:08:11.520905Z"},"id":"de447bee","outputId":"511c7a71-48c7-43cd-805f-f9db5c810f75"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2164, 807, 637]\n","3608\n"]}],"source":["# results = parse_SemEval14('Restaurants_Train.xml')"]},{"cell_type":"code","execution_count":null,"id":"cf6533ae","metadata":{"ExecuteTime":{"end_time":"2022-03-12T17:08:31.035995Z","start_time":"2022-03-12T17:08:30.998283Z"},"id":"cf6533ae","outputId":"92c47313-45f7-4557-af40-479896178772"},"outputs":[{"data":{"text/plain":["{'id': '3121_0',\n"," 'sentence': 'But the staff was so horrible to us.',\n"," 'term': 'staff',\n"," 'polarity': 'negative'}"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# results[0]"]},{"cell_type":"markdown","id":"61a59010","metadata":{"id":"61a59010"},"source":["## Useful functions"]},{"cell_type":"code","execution_count":null,"id":"afb672ac","metadata":{"ExecuteTime":{"end_time":"2022-03-13T10:08:45.676103Z","start_time":"2022-03-13T10:08:40.903122Z"},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["27df3c677b2f451f8f55e7af2fc670b9","a95880fab6cd46edbdc319588006a028","036c305fbf374ebe8ee1a591c930b5e5","e3fe846f06344fa88d6764e4b8d267f5","5ad800b4385f4e0385538a285e4fe2fc","6841e7728e7642cc831ca76009985c3d","958b976a20e14bb0ac435471492c8d77","b210722ed33349589016199c25c174a2","167fbe3c61604f039257af6561c3289b","e8a48efd25104b4f85168759ba4f4df3","18f3cd59e4724a58b9ee31614a87b401","d2d848883d234c5b8bee408442fb3750","46cb6f89ed85438ab305fcf822c480fa","37b80b7becf5429f8b7524aa0fbea01e","d925e379051d4575b7f1eb108599af0f","0f6acf3cf502416ab6505da39c807778","d85c3ce16bcf412c9adb144ea2369937","e1769bc870ae4292bbd15955696a66f4","ec2c8ad1a5214b919ad4a8b1f3475a61","9811c4f516e04dd096e0d2cd97d2ef06","5f4a489f495e435687baf4991fe8da0e","a0e241a3d65f45f8b74910d0fdb335a7","626f44727cf34344917b5b9cc4c1d21e","aa73dc55b018479eb96ec783a9d35f17","c72719690a334e3b880ce2b7eb83fa96","18c026b3af404f30bc18c112eaff3f7b","0d56200c42474a9fa5857bdf1ee2770e","f845a1a2b0c749048afd808e2facca45","ec7a2d5f833a4274ad0bce23a1673be1","bd7cf3a587ef4ede860a66d554e93045","e01267b39f0b4ff5b249f53c7b67dc29","173051adab2a49b0818a8ee44151982a","d43082a0398d4b40a079257be07eaf5f","f2ba90fef4f340f2985f19ad04592406","5d06eae7bdc64c1cbed0a9e798148174","9af9aa463f5644e98237c21e1a937e89","3713b02f655649878e521a0c415a522b","41ea6be81205418fa23f83b75f32c79a","c0200b2e02f84425a13b6b99a20e5263","f9eb1c74849a437ab7e1bcba91f1d51e","ecbb5054940d4882a0fccb29fd7b2d66","b3f0d0f1ea0941f1a14e629442058c67","ce4d48f7ef134df1a5a111235d8bc05f","adfde3899ef6426b9a7960eff9b12ecf"]},"id":"afb672ac","executionInfo":{"status":"ok","timestamp":1647184600188,"user_tz":-60,"elapsed":882,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"dcb6b74c-8451-409a-85b5-ba24cb68fc5c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27df3c677b2f451f8f55e7af2fc670b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2d848883d234c5b8bee408442fb3750"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"626f44727cf34344917b5b9cc4c1d21e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2ba90fef4f340f2985f19ad04592406"}},"metadata":{}}],"source":["from transformers import BertTokenizer\n","# tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n","tokenizer = AutoTokenizer.from_pretrained(\"activebus/BERT-XD_Review\")"]},{"cell_type":"code","execution_count":null,"id":"c4045531","metadata":{"ExecuteTime":{"end_time":"2022-03-13T10:10:10.097402Z","start_time":"2022-03-13T10:10:10.092562Z"},"id":"c4045531"},"outputs":[],"source":["def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            tokens_b.pop()"]},{"cell_type":"code","execution_count":null,"id":"b4a751f9","metadata":{"ExecuteTime":{"end_time":"2022-03-13T10:13:57.025836Z","start_time":"2022-03-13T10:13:57.019738Z"},"id":"b4a751f9"},"outputs":[],"source":["class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_id = label_id\n"]},{"cell_type":"code","execution_count":null,"id":"13baf7f2","metadata":{"ExecuteTime":{"end_time":"2022-03-13T10:13:58.515179Z","start_time":"2022-03-13T10:13:58.505007Z"},"id":"13baf7f2"},"outputs":[],"source":["def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n","    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\" #check later if we can merge this function with the SQuAD preprocessing \n","    label_map = {}\n","    for (i, label) in enumerate(label_list):\n","        label_map[label] = i\n","\n","    features = []\n","    for (ex_index, example) in enumerate(examples):\n","        tokens_a =tokenizer.tokenize(example.text_a)\n","        tokens_b = None\n","        if example.text_b:\n","            tokens_b = tokenizer.tokenize(example.text_b)\n","\n","        if tokens_b:\n","            # Modifies `tokens_a` and `tokens_b` in place so that the total\n","            # length is less than the specified length.\n","            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n","        else:\n","            # Account for [CLS] and [SEP] with \"- 2\"\n","            if len(tokens_a) > max_seq_length - 2:\n","                tokens_a = tokens_a[0:(max_seq_length - 2)]\n","\n","        tokens = []\n","        segment_ids = []\n","        tokens.append(\"[CLS]\")\n","        segment_ids.append(0)\n","        for token in tokens_a:\n","            tokens.append(token)\n","            segment_ids.append(0)\n","        tokens.append(\"[SEP]\")\n","        segment_ids.append(0)\n","\n","        if tokens_b:\n","            for token in tokens_b:\n","                tokens.append(token)\n","                segment_ids.append(1)\n","            tokens.append(\"[SEP]\")\n","            segment_ids.append(1)\n","\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","        # tokens are attended to.\n","        input_mask = [1] * len(input_ids)\n","\n","        # Zero-pad up to the sequence length.\n","        while len(input_ids) < max_seq_length:\n","            input_ids.append(0)\n","            input_mask.append(0)\n","            segment_ids.append(0)\n","\n","        assert len(input_ids) == max_seq_length\n","        assert len(input_mask) == max_seq_length\n","        assert len(segment_ids) == max_seq_length\n","\n","        \n","        label_id = label_map[example.label]\n","\n","        features.append(\n","                InputFeatures(\n","                        input_ids=input_ids,\n","                        input_mask=input_mask,\n","                        segment_ids=segment_ids,\n","                        label_id=label_id))\n","    return features\n"]},{"cell_type":"code","execution_count":null,"id":"ab52e3cd","metadata":{"ExecuteTime":{"end_time":"2022-03-12T16:13:03.985672Z","start_time":"2022-03-12T16:13:03.975527Z"},"id":"ab52e3cd"},"outputs":[],"source":["def _create_examples(dataset, set_type):\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\n","        \"\"\"\n","        Parameters:\n","        dataset:\n","        set_type:'train'/'test'\n","        '\"\"\"\n","        examples = []\n","        for index, row in dataset.iterrows():\n","            guid = \"%s-%s\" % (set_type, index )\n","            text_a = row['target']\n","            text_b = row['sentence']\n","            label = row['polarity']\n","            examples.append(\n","                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n","        return examples  "]},{"cell_type":"code","execution_count":null,"id":"8ca8de79","metadata":{"ExecuteTime":{"end_time":"2022-03-13T11:27:23.277406Z","start_time":"2022-03-13T11:27:23.273536Z"},"id":"8ca8de79"},"outputs":[],"source":["def warmup_linear(x, warmup=0.002):\n","    if x < warmup:\n","        return x/warmup\n","    return 1.0 - x"]},{"cell_type":"code","execution_count":null,"id":"8babde02","metadata":{"ExecuteTime":{"end_time":"2022-03-12T16:11:03.208817Z","start_time":"2022-03-12T16:11:03.203418Z"},"id":"8babde02"},"outputs":[],"source":["class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text_a, text_b=None, label=None):\n","        \"\"\"Constructs a InputExample.\n","        Args:\n","            guid: Unique id for the example.\n","            text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","            text_b: (Optional) string. The untokenized text of the second sequence.\n","            Only must be specified for sequence pair tasks.\n","            label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.label = label"]},{"cell_type":"markdown","source":["## Model training"],"metadata":{"id":"kH6h_am43Af5"},"id":"kH6h_am43Af5"},{"cell_type":"code","execution_count":null,"id":"88dd665c","metadata":{"ExecuteTime":{"end_time":"2022-03-13T11:27:26.515981Z","start_time":"2022-03-13T11:27:26.502765Z"},"id":"88dd665c"},"outputs":[],"source":["def train(dataset, batch_size = 12, epochs=5, max_seq_length = 138, learning_rate = 3e-5,warmup_proportion=0.1):\n","#     processor = data_utils.AscProcessor()\n","    label_list = [\"positive\", \"negative\", \"neutral\"]\n","    train_examples = _create_examples(train_set,'train')\n","    num_train_steps = int(len(train_examples) / batch_size) * epochs\n","\n","    train_features = convert_examples_to_features(\n","        train_examples, label_list, max_seq_length, tokenizer)\n","#     logger.info(\"***** Running training *****\")\n","#     logger.info(\"  Num examples = %d\", len(train_examples))\n","#     logger.info(\"  Batch size = %d\", args.train_batch_size)\n","#     logger.info(\"  Num steps = %d\", num_train_steps)\n","    \n","    all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n","\n","    all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n","\n","    all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n","\n","    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n","\n","    \n","    train_data = TensorDataset(all_input_ids, all_segment_ids, all_input_mask, all_label_ids)\n","\n","    train_sampler = RandomSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","    \n","#     #>>>>> validation\n","#     if args.do_valid:\n","#         valid_examples = processor.get_dev_examples(args.data_dir)\n","#         valid_features=data_utils.convert_examples_to_features(\n","#             valid_examples, label_list, args.max_seq_length, tokenizer, \"asc\")\n","#         valid_all_input_ids = torch.tensor([f.input_ids for f in valid_features], dtype=torch.long)\n","#         valid_all_segment_ids = torch.tensor([f.segment_ids for f in valid_features], dtype=torch.long)\n","#         valid_all_input_mask = torch.tensor([f.input_mask for f in valid_features], dtype=torch.long)\n","#         valid_all_label_ids = torch.tensor([f.label_id for f in valid_features], dtype=torch.long)\n","#         valid_data = TensorDataset(valid_all_input_ids, valid_all_segment_ids, valid_all_input_mask, valid_all_label_ids)\n","\n","#         logger.info(\"***** Running validations *****\")\n","#         logger.info(\"  Num orig examples = %d\", len(valid_examples))\n","#         logger.info(\"  Num split examples = %d\", len(valid_features))\n","#         logger.info(\"  Batch size = %d\", args.train_batch_size)\n","\n","#         valid_sampler = SequentialSampler(valid_data)\n","#         valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=args.train_batch_size)    \n","\n","#         best_valid_loss=float('inf')\n","#         valid_losses=[]\n","#     #<<<<< end of validation declaration\n","\n","#     model = AutoModel.from_pretrained(\"activebus/BERT-XD_Review\")\n","    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = len(label_list) )\n","    model.to(device)\n","    # Prepare optimizer\n","    param_optimizer = [(k, v) for k, v in model.named_parameters() if v.requires_grad==True]\n","    param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n","    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","    t_total = num_train_steps\n","    optimizer = BertAdam(optimizer_grouped_parameters,\n","                         lr=learning_rate,\n","                         warmup=warmup_proportion,\n","                         t_total=t_total)\n","\n","    global_step = 0\n","    model.train()\n","    for _ in range(epochs):\n","        for step, batch in enumerate(tqdm(train_dataloader)):\n","            batch = tuple(t.to(device) for t in batch)\n","            input_ids, segment_ids, input_mask, label_ids = batch\n","            loss = model(input_ids, segment_ids, input_mask, label_ids)\n","            loss.backward()\n","\n","            lr_this_step = learning_rate * warmup_linear(global_step/t_total,warmup_proportion)\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = lr_this_step\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            global_step += 1\n","#             #>>>> perform validation at the end of each epoch .\n","#         if args.do_valid:\n","#             model.eval()\n","#             with torch.no_grad():\n","#                 losses=[]\n","#                 valid_size=0\n","#                 for step, batch in enumerate(valid_dataloader):\n","#                     batch = tuple(t.cuda() for t in batch) # multi-gpu does scattering it-self\n","#                     input_ids, segment_ids, input_mask, label_ids = batch\n","#                     loss = model(input_ids, segment_ids, input_mask, label_ids)\n","#                     losses.append(loss.data.item()*input_ids.size(0) )\n","#                     valid_size+=input_ids.size(0)\n","#                 valid_loss=sum(losses)/valid_size\n","#                 logger.info(\"validation loss: %f\", valid_loss)\n","#                 valid_losses.append(valid_loss)\n","#             if valid_loss<best_valid_loss:\n","#                 torch.save(model, os.path.join(args.output_dir, \"model.pt\") )\n","#                 best_valid_loss=valid_loss\n","#             model.train()\n","#     if args.do_valid:\n","#         with open(os.path.join(args.output_dir, \"valid.json\"), \"w\") as fw:\n","#             json.dump({\"valid_losses\": valid_losses}, fw)\n","#     else:\n","    torch.save(model,  \"model.pt\" )\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"9ed20351","metadata":{"ExecuteTime":{"end_time":"2022-03-13T13:43:55.612093Z","start_time":"2022-03-13T11:27:30.517116Z"},"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"9ed20351","executionInfo":{"status":"ok","timestamp":1647185202206,"user_tz":-60,"elapsed":267585,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"4c8ae66a-d3b3-414d-bdd1-e1dd4f388e57"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 407873900/407873900 [00:12<00:00, 33405912.86B/s]\n","  0%|          | 0/126 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","100%|██████████| 126/126 [00:45<00:00,  2.78it/s]\n","100%|██████████| 126/126 [00:46<00:00,  2.69it/s]\n","100%|██████████| 126/126 [00:47<00:00,  2.66it/s]\n","100%|██████████| 126/126 [00:47<00:00,  2.67it/s]\n"," 97%|█████████▋| 122/126 [00:46<00:01,  2.64it/s]Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"," 98%|█████████▊| 123/126 [00:46<00:01,  2.64it/s]Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"," 98%|█████████▊| 124/126 [00:47<00:00,  2.64it/s]Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"," 99%|█████████▉| 125/126 [00:47<00:00,  2.65it/s]Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","100%|██████████| 126/126 [00:47<00:00,  2.65it/s]\n"]}],"source":["train(train_set)"]},{"cell_type":"markdown","source":["## Model evaluation"],"metadata":{"id":"r7nyx7tt3E83"},"id":"r7nyx7tt3E83"},{"cell_type":"code","execution_count":null,"id":"e66bc67f","metadata":{"ExecuteTime":{"end_time":"2022-03-13T14:15:05.223681Z","start_time":"2022-03-13T14:15:05.187230Z"},"id":"e66bc67f"},"outputs":[],"source":["def test(dataset,max_seq_length=128, batch_size=6):  \n","    # Load a trained model that you have fine-tuned (we assume evaluate on cpu)    \n","\n","    label_list = [\"positive\", \"negative\", \"neutral\"]\n","    eval_examples = _create_examples(dataset,'test')\n","    \n","#     tokenizer = BertTokenizer.from_pretrained(modelconfig.MODEL_ARCHIVE_MAP[args.bert_model])\n","\n","    eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer)\n","\n","\n","    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n","    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n","    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n","    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n","    eval_data = TensorDataset(all_input_ids, all_segment_ids, all_input_mask, all_label_ids)\n","    # Run prediction for full data\n","    eval_sampler = SequentialSampler(eval_data)\n","    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=batch_size)\n","\n","    model = torch.load(\"model.pt\")\n","    model.to(device)\n","    model.eval()\n","    \n","    full_logits=[]\n","    predicted_labels=[]\n","    full_label_ids=[]\n","    for step, batch in enumerate(tqdm(eval_dataloader)):\n","        batch = tuple(t.to(device) for t in batch)\n","#         batch = tuple(t.cuda() for t in batch)\n","        input_ids, segment_ids, input_mask, label_ids = batch\n","        \n","        with torch.no_grad():\n","            logits = model(input_ids, segment_ids, input_mask)\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = label_ids.cpu().numpy()\n","\n","        full_logits.extend(logits.tolist() )\n","        full_label_ids.extend(label_ids.tolist() )\n","        predicted_labels = np.argmax(full_logits, axis=1)\n","\n","    return predicted_labels, full_label_ids\n","\n"]},{"cell_type":"code","execution_count":null,"id":"f82e4ce8","metadata":{"ExecuteTime":{"end_time":"2022-03-13T14:06:35.963888Z","start_time":"2022-03-13T14:06:35.955454Z"},"id":"f82e4ce8"},"outputs":[],"source":["# Evaluation\n","def load_label_output(filename):\n","    with open(filename, 'r', encoding='UTF-8') as f:\n","        return [line.strip().split(\"\\t\")[0] for line in f if line.strip()]\n","\n","def eval_list(glabels, slabels):\n","    if (len(glabels) != len(slabels)):\n","        print(\"\\nWARNING: label count in system output (%d) is different from gold label count (%d)\\n\" % (\n","        len(slabels), len(glabels)))\n","    n = min(len(slabels), len(glabels))\n","    incorrect_count = 0\n","    for i in range(n):\n","        if slabels[i] != glabels[i]: incorrect_count += 1\n","    acc = (n - incorrect_count) / n\n","    return acc*100\n"]},{"cell_type":"code","execution_count":null,"id":"3b7e270a","metadata":{"ExecuteTime":{"end_time":"2022-03-13T14:17:17.225401Z","start_time":"2022-03-13T14:15:32.304322Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"3b7e270a","executionInfo":{"status":"ok","timestamp":1647185297289,"user_tz":-60,"elapsed":3758,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"36447cd7-3d02-45b0-ab1f-877216598cae"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 63/63 [00:03<00:00, 19.35it/s]\n"]}],"source":["slabel_ids,glabel_ids = test(val_set)"]},{"cell_type":"code","execution_count":null,"id":"60b8e974","metadata":{"ExecuteTime":{"end_time":"2022-03-13T14:12:55.757370Z","start_time":"2022-03-13T14:12:55.729298Z"},"id":"60b8e974"},"outputs":[],"source":["label_dict = {0:'positive',1:'negative',2:'neutral'}\n","slabels = [label_dict[i] for i in slabel_ids]"]},{"cell_type":"code","execution_count":null,"id":"487f3130","metadata":{"ExecuteTime":{"end_time":"2022-03-13T14:22:18.854454Z","start_time":"2022-03-13T14:22:18.850501Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"487f3130","executionInfo":{"status":"ok","timestamp":1647185301826,"user_tz":-60,"elapsed":569,"user":{"displayName":"Miao WANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBqjjW4zzJr9gfTMzWY0Bhdfi_5usoESlQXzlM=s64","userId":"01565474498039976052"}},"outputId":"0d817274-888b-491c-a42e-8d5caa828f14"},"outputs":[{"output_type":"stream","name":"stdout","text":["the accuracy of predictions: 83.51 %\n"]}],"source":["print('the accuracy of predictions:', format(eval_list(glabel_ids,slabel_ids),'.2f'),'%')"]},{"cell_type":"code","execution_count":null,"id":"ced6300d","metadata":{"id":"ced6300d"},"outputs":[],"source":["# Reference: https://aclanthology.org/W19-6120.pdf\n","# Pre-processing entity and aspect pairs for BERT\n","\n","# In order to fit better the BERT model when training and to be able have the pretrained data in BERT to be applicable, \n","# we formatted it to have a sentence-like structure, so the pair ”FOOD#STYLE OPTIONS” gets parsed into ”food, style options”. \n","# This text is what we use as aspect.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c67b07e3","metadata":{"id":"c67b07e3"},"outputs":[],"source":["# Fix class imbalance\n","\n","# To compensate for the imbalance, we weight each label depending on how frequently they show up in the training set. \n","# The higher the frequency of a label, the lower the weight of the given label.\n","\n"]},{"cell_type":"markdown","id":"78fb28b6","metadata":{"id":"78fb28b6"},"source":["# Sentiment terms"]},{"cell_type":"code","execution_count":null,"id":"7ba9a95e","metadata":{"id":"7ba9a95e"},"outputs":[],"source":["# Get the sentiment terms\n","\n","sentiment_terms = []\n","for review in nlp.pipe(train_set['sentence']):\n","        if review.is_parsed:\n","            sentiment_terms.append(' '.join([token.lemma_ for token in review if (not token.is_stop and not token.is_punct and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\"))]))\n","        else:\n","            sentiment_terms.append('')  \n","train_set['sentiment_terms'] = sentiment_terms\n","train_set.head(10)"]},{"cell_type":"code","execution_count":null,"id":"75708b96","metadata":{"id":"75708b96"},"outputs":[],"source":["# Build the sentiment model\n","sentiment_model = Sequential()\n","sentiment_model.add(Dense(512, input_shape=(6000,), activation='relu'))\n","sentiment_model.add(Dense(3, activation='softmax'))\n","sentiment_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","sentiment_tokenized = pd.DataFrame(tokenizer.texts_to_matrix(dataset.sentiment_terms))\n","\n","label_encoder_2 = LabelEncoder()\n","integer_sentiment = label_encoder_2.fit_transform(dataset.sentiment)\n","dummy_sentiment = to_categorical(integer_sentiment)\n","\n","sentiment_model.fit(sentiment_tokenized, dummy_sentiment, epochs=5, verbose=1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"288px"},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"BertSequenceClassifier.ipynb","provenance":[],"collapsed_sections":["8b548efa"]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"27df3c677b2f451f8f55e7af2fc670b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a95880fab6cd46edbdc319588006a028","IPY_MODEL_036c305fbf374ebe8ee1a591c930b5e5","IPY_MODEL_e3fe846f06344fa88d6764e4b8d267f5"],"layout":"IPY_MODEL_5ad800b4385f4e0385538a285e4fe2fc"}},"a95880fab6cd46edbdc319588006a028":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6841e7728e7642cc831ca76009985c3d","placeholder":"​","style":"IPY_MODEL_958b976a20e14bb0ac435471492c8d77","value":"Downloading: 100%"}},"036c305fbf374ebe8ee1a591c930b5e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b210722ed33349589016199c25c174a2","max":39,"min":0,"orientation":"horizontal","style":"IPY_MODEL_167fbe3c61604f039257af6561c3289b","value":39}},"e3fe846f06344fa88d6764e4b8d267f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8a48efd25104b4f85168759ba4f4df3","placeholder":"​","style":"IPY_MODEL_18f3cd59e4724a58b9ee31614a87b401","value":" 39.0/39.0 [00:00&lt;00:00, 1.01kB/s]"}},"5ad800b4385f4e0385538a285e4fe2fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6841e7728e7642cc831ca76009985c3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"958b976a20e14bb0ac435471492c8d77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b210722ed33349589016199c25c174a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"167fbe3c61604f039257af6561c3289b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8a48efd25104b4f85168759ba4f4df3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f3cd59e4724a58b9ee31614a87b401":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2d848883d234c5b8bee408442fb3750":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46cb6f89ed85438ab305fcf822c480fa","IPY_MODEL_37b80b7becf5429f8b7524aa0fbea01e","IPY_MODEL_d925e379051d4575b7f1eb108599af0f"],"layout":"IPY_MODEL_0f6acf3cf502416ab6505da39c807778"}},"46cb6f89ed85438ab305fcf822c480fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d85c3ce16bcf412c9adb144ea2369937","placeholder":"​","style":"IPY_MODEL_e1769bc870ae4292bbd15955696a66f4","value":"Downloading: 100%"}},"37b80b7becf5429f8b7524aa0fbea01e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec2c8ad1a5214b919ad4a8b1f3475a61","max":1020,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9811c4f516e04dd096e0d2cd97d2ef06","value":1020}},"d925e379051d4575b7f1eb108599af0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f4a489f495e435687baf4991fe8da0e","placeholder":"​","style":"IPY_MODEL_a0e241a3d65f45f8b74910d0fdb335a7","value":" 1.00k/1.00k [00:00&lt;00:00, 32.7kB/s]"}},"0f6acf3cf502416ab6505da39c807778":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d85c3ce16bcf412c9adb144ea2369937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1769bc870ae4292bbd15955696a66f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec2c8ad1a5214b919ad4a8b1f3475a61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9811c4f516e04dd096e0d2cd97d2ef06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f4a489f495e435687baf4991fe8da0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0e241a3d65f45f8b74910d0fdb335a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"626f44727cf34344917b5b9cc4c1d21e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa73dc55b018479eb96ec783a9d35f17","IPY_MODEL_c72719690a334e3b880ce2b7eb83fa96","IPY_MODEL_18c026b3af404f30bc18c112eaff3f7b"],"layout":"IPY_MODEL_0d56200c42474a9fa5857bdf1ee2770e"}},"aa73dc55b018479eb96ec783a9d35f17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f845a1a2b0c749048afd808e2facca45","placeholder":"​","style":"IPY_MODEL_ec7a2d5f833a4274ad0bce23a1673be1","value":"Downloading: 100%"}},"c72719690a334e3b880ce2b7eb83fa96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd7cf3a587ef4ede860a66d554e93045","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e01267b39f0b4ff5b249f53c7b67dc29","value":231508}},"18c026b3af404f30bc18c112eaff3f7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_173051adab2a49b0818a8ee44151982a","placeholder":"​","style":"IPY_MODEL_d43082a0398d4b40a079257be07eaf5f","value":" 226k/226k [00:00&lt;00:00, 5.13MB/s]"}},"0d56200c42474a9fa5857bdf1ee2770e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f845a1a2b0c749048afd808e2facca45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec7a2d5f833a4274ad0bce23a1673be1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd7cf3a587ef4ede860a66d554e93045":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e01267b39f0b4ff5b249f53c7b67dc29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"173051adab2a49b0818a8ee44151982a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d43082a0398d4b40a079257be07eaf5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2ba90fef4f340f2985f19ad04592406":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d06eae7bdc64c1cbed0a9e798148174","IPY_MODEL_9af9aa463f5644e98237c21e1a937e89","IPY_MODEL_3713b02f655649878e521a0c415a522b"],"layout":"IPY_MODEL_41ea6be81205418fa23f83b75f32c79a"}},"5d06eae7bdc64c1cbed0a9e798148174":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0200b2e02f84425a13b6b99a20e5263","placeholder":"​","style":"IPY_MODEL_f9eb1c74849a437ab7e1bcba91f1d51e","value":"Downloading: 100%"}},"9af9aa463f5644e98237c21e1a937e89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecbb5054940d4882a0fccb29fd7b2d66","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3f0d0f1ea0941f1a14e629442058c67","value":112}},"3713b02f655649878e521a0c415a522b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce4d48f7ef134df1a5a111235d8bc05f","placeholder":"​","style":"IPY_MODEL_adfde3899ef6426b9a7960eff9b12ecf","value":" 112/112 [00:00&lt;00:00, 3.40kB/s]"}},"41ea6be81205418fa23f83b75f32c79a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0200b2e02f84425a13b6b99a20e5263":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9eb1c74849a437ab7e1bcba91f1d51e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecbb5054940d4882a0fccb29fd7b2d66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3f0d0f1ea0941f1a14e629442058c67":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce4d48f7ef134df1a5a111235d8bc05f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adfde3899ef6426b9a7960eff9b12ecf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}